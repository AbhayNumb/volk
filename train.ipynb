{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11366,"status":"ok","timestamp":1699182960368,"user":{"displayName":"Numb 511","userId":"14359729300254156022"},"user_tz":-330},"id":"WA4Dq-w4MTOz","outputId":"1c11ad04-cc99-4a8d-8b2f-26ec8d12ed0a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","2/2 [==============================] - 1s 217ms/step - loss: 0.3124 - mae: 0.4928 - val_loss: 0.3586 - val_mae: 0.5429\n","Epoch 2/50\n","2/2 [==============================] - 0s 36ms/step - loss: 0.2832 - mae: 0.4617 - val_loss: 0.3285 - val_mae: 0.5144\n","Epoch 3/50\n","2/2 [==============================] - 0s 42ms/step - loss: 0.2567 - mae: 0.4325 - val_loss: 0.3003 - val_mae: 0.4862\n","Epoch 4/50\n","2/2 [==============================] - 0s 52ms/step - loss: 0.2327 - mae: 0.4039 - val_loss: 0.2735 - val_mae: 0.4578\n","Epoch 5/50\n","2/2 [==============================] - 0s 39ms/step - loss: 0.2102 - mae: 0.3755 - val_loss: 0.2474 - val_mae: 0.4287\n","Epoch 6/50\n","2/2 [==============================] - 0s 53ms/step - loss: 0.1892 - mae: 0.3483 - val_loss: 0.2226 - val_mae: 0.3991\n","Epoch 7/50\n","2/2 [==============================] - 0s 33ms/step - loss: 0.1693 - mae: 0.3241 - val_loss: 0.1988 - val_mae: 0.3700\n","Epoch 8/50\n","2/2 [==============================] - 0s 37ms/step - loss: 0.1501 - mae: 0.2998 - val_loss: 0.1750 - val_mae: 0.3399\n","Epoch 9/50\n","2/2 [==============================] - 0s 34ms/step - loss: 0.1330 - mae: 0.2766 - val_loss: 0.1518 - val_mae: 0.3107\n","Epoch 10/50\n","2/2 [==============================] - 0s 33ms/step - loss: 0.1168 - mae: 0.2570 - val_loss: 0.1310 - val_mae: 0.2838\n","Epoch 11/50\n","2/2 [==============================] - 0s 34ms/step - loss: 0.1033 - mae: 0.2397 - val_loss: 0.1130 - val_mae: 0.2592\n","Epoch 12/50\n","2/2 [==============================] - 0s 34ms/step - loss: 0.0916 - mae: 0.2251 - val_loss: 0.0976 - val_mae: 0.2370\n","Epoch 13/50\n","2/2 [==============================] - 0s 33ms/step - loss: 0.0836 - mae: 0.2132 - val_loss: 0.0845 - val_mae: 0.2161\n","Epoch 14/50\n","2/2 [==============================] - 0s 34ms/step - loss: 0.0769 - mae: 0.2050 - val_loss: 0.0740 - val_mae: 0.2065\n","Epoch 15/50\n","2/2 [==============================] - 0s 52ms/step - loss: 0.0729 - mae: 0.2033 - val_loss: 0.0653 - val_mae: 0.2009\n","Epoch 16/50\n","2/2 [==============================] - 0s 37ms/step - loss: 0.0713 - mae: 0.2057 - val_loss: 0.0590 - val_mae: 0.1981\n","Epoch 17/50\n","2/2 [==============================] - 0s 36ms/step - loss: 0.0702 - mae: 0.2103 - val_loss: 0.0551 - val_mae: 0.1956\n","Epoch 18/50\n","2/2 [==============================] - 0s 34ms/step - loss: 0.0691 - mae: 0.2117 - val_loss: 0.0524 - val_mae: 0.1933\n","Epoch 19/50\n","2/2 [==============================] - 0s 51ms/step - loss: 0.0690 - mae: 0.2132 - val_loss: 0.0500 - val_mae: 0.1911\n","Epoch 20/50\n","2/2 [==============================] - 0s 42ms/step - loss: 0.0687 - mae: 0.2143 - val_loss: 0.0483 - val_mae: 0.1894\n","Epoch 21/50\n","2/2 [==============================] - 0s 38ms/step - loss: 0.0683 - mae: 0.2143 - val_loss: 0.0473 - val_mae: 0.1883\n","Epoch 22/50\n","2/2 [==============================] - 0s 38ms/step - loss: 0.0676 - mae: 0.2135 - val_loss: 0.0463 - val_mae: 0.1874\n","Epoch 23/50\n","2/2 [==============================] - 0s 60ms/step - loss: 0.0670 - mae: 0.2127 - val_loss: 0.0457 - val_mae: 0.1866\n","Epoch 24/50\n","2/2 [==============================] - 0s 38ms/step - loss: 0.0659 - mae: 0.2108 - val_loss: 0.0459 - val_mae: 0.1861\n","Epoch 25/50\n","2/2 [==============================] - 0s 34ms/step - loss: 0.0645 - mae: 0.2077 - val_loss: 0.0465 - val_mae: 0.1854\n","Epoch 26/50\n","2/2 [==============================] - 0s 34ms/step - loss: 0.0629 - mae: 0.2035 - val_loss: 0.0474 - val_mae: 0.1845\n","Epoch 27/50\n","2/2 [==============================] - 0s 57ms/step - loss: 0.0618 - mae: 0.1996 - val_loss: 0.0487 - val_mae: 0.1838\n","Epoch 28/50\n","2/2 [==============================] - 0s 52ms/step - loss: 0.0607 - mae: 0.1955 - val_loss: 0.0505 - val_mae: 0.1835\n","Epoch 29/50\n","2/2 [==============================] - 0s 34ms/step - loss: 0.0601 - mae: 0.1929 - val_loss: 0.0525 - val_mae: 0.1837\n","Epoch 30/50\n","2/2 [==============================] - 0s 33ms/step - loss: 0.0599 - mae: 0.1909 - val_loss: 0.0537 - val_mae: 0.1851\n","Epoch 31/50\n","2/2 [==============================] - 0s 51ms/step - loss: 0.0595 - mae: 0.1893 - val_loss: 0.0540 - val_mae: 0.1853\n","Epoch 32/50\n","2/2 [==============================] - 0s 32ms/step - loss: 0.0591 - mae: 0.1883 - val_loss: 0.0543 - val_mae: 0.1852\n","Epoch 33/50\n","2/2 [==============================] - 0s 36ms/step - loss: 0.0587 - mae: 0.1872 - val_loss: 0.0545 - val_mae: 0.1848\n","Epoch 34/50\n","2/2 [==============================] - 0s 34ms/step - loss: 0.0584 - mae: 0.1861 - val_loss: 0.0545 - val_mae: 0.1842\n","Epoch 35/50\n","2/2 [==============================] - 0s 38ms/step - loss: 0.0579 - mae: 0.1851 - val_loss: 0.0543 - val_mae: 0.1829\n","Epoch 36/50\n","2/2 [==============================] - 0s 33ms/step - loss: 0.0575 - mae: 0.1841 - val_loss: 0.0537 - val_mae: 0.1820\n","Epoch 37/50\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0570 - mae: 0.1837 - val_loss: 0.0531 - val_mae: 0.1811\n","Epoch 38/50\n","2/2 [==============================] - 0s 55ms/step - loss: 0.0564 - mae: 0.1832 - val_loss: 0.0524 - val_mae: 0.1800\n","Epoch 39/50\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0558 - mae: 0.1823 - val_loss: 0.0513 - val_mae: 0.1782\n","Epoch 40/50\n","2/2 [==============================] - 0s 36ms/step - loss: 0.0555 - mae: 0.1821 - val_loss: 0.0499 - val_mae: 0.1775\n","Epoch 41/50\n","2/2 [==============================] - 0s 35ms/step - loss: 0.0548 - mae: 0.1818 - val_loss: 0.0484 - val_mae: 0.1766\n","Epoch 42/50\n","2/2 [==============================] - 0s 48ms/step - loss: 0.0545 - mae: 0.1820 - val_loss: 0.0469 - val_mae: 0.1754\n","Epoch 43/50\n","2/2 [==============================] - 0s 47ms/step - loss: 0.0540 - mae: 0.1818 - val_loss: 0.0460 - val_mae: 0.1746\n","Epoch 44/50\n","2/2 [==============================] - 0s 37ms/step - loss: 0.0536 - mae: 0.1814 - val_loss: 0.0451 - val_mae: 0.1738\n","Epoch 45/50\n","2/2 [==============================] - 0s 35ms/step - loss: 0.0532 - mae: 0.1810 - val_loss: 0.0442 - val_mae: 0.1729\n","Epoch 46/50\n","2/2 [==============================] - 0s 54ms/step - loss: 0.0528 - mae: 0.1805 - val_loss: 0.0436 - val_mae: 0.1723\n","Epoch 47/50\n","2/2 [==============================] - 0s 36ms/step - loss: 0.0524 - mae: 0.1798 - val_loss: 0.0433 - val_mae: 0.1719\n","Epoch 48/50\n","2/2 [==============================] - 0s 35ms/step - loss: 0.0521 - mae: 0.1792 - val_loss: 0.0433 - val_mae: 0.1717\n","Epoch 49/50\n","2/2 [==============================] - 0s 52ms/step - loss: 0.0517 - mae: 0.1783 - val_loss: 0.0438 - val_mae: 0.1718\n","Epoch 50/50\n","2/2 [==============================] - 0s 34ms/step - loss: 0.0513 - mae: 0.1772 - val_loss: 0.0445 - val_mae: 0.1720\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0445 - mae: 0.1720\n","Test Loss: 0.04446667060256004, Test Mean Absolute Error: 0.17204207181930542\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from sklearn.model_selection import train_test_split\n","\n","# Load and preprocess the sample data from \"sample.txt\"\n","def load_training_data(file_path):\n","    X = []\n","    y = []\n","    with open(file_path, \"r\") as file:\n","        lines = file.readlines()\n","        for line in lines:\n","            data = line.strip().split(\":\")\n","            X_data = list(map(float, data[0].split(\",\")))\n","            y_data = list(map(float, data[1].split(\",\")))\n","            X.append(X_data)\n","            y.append(y_data)\n","    return np.array(X), np.array(y)\n","\n","X_train, y_train = load_training_data(\"/content/sample.txt\")\n","\n","# Split the data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n","\n","# Create a simple neural network model\n","model = keras.Sequential([\n","    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n","    layers.Dense(32, activation='relu'),\n","    layers.Dense(y_train.shape[1])  # Output layer with the same number of units as the output data\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n","\n","# Train the model\n","history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n","\n","# Evaluate the model\n","test_loss, test_mae = model.evaluate(X_val, y_val)\n","print(f\"Test Loss: {test_loss}, Test Mean Absolute Error: {test_mae}\")\n","\n","# Save the trained model\n","model.save('sample_model.h5')\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOpo9qzZCN5PCzXPkNf9Ot/","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
